{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-08-11T14:08:57.924094Z",
     "iopub.status.busy": "2022-08-11T14:08:57.922956Z",
     "iopub.status.idle": "2022-08-11T14:08:57.946573Z",
     "shell.execute_reply": "2022-08-11T14:08:57.945607Z",
     "shell.execute_reply.started": "2022-08-11T14:08:57.924053Z"
    }
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-11T14:08:57.968990Z",
     "iopub.status.busy": "2022-08-11T14:08:57.967847Z",
     "iopub.status.idle": "2022-08-11T14:09:27.535893Z",
     "shell.execute_reply": "2022-08-11T14:09:27.534407Z",
     "shell.execute_reply.started": "2022-08-11T14:08:57.968943Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install pycrf\n",
    "!pip install sklearn-crfsuite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-11T14:09:27.539067Z",
     "iopub.status.busy": "2022-08-11T14:09:27.538619Z",
     "iopub.status.idle": "2022-08-11T14:09:32.913131Z",
     "shell.execute_reply": "2022-08-11T14:09:32.911698Z",
     "shell.execute_reply.started": "2022-08-11T14:09:27.539024Z"
    }
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "import textwrap\n",
    "import warnings\n",
    "import json\n",
    "import sklearn_crfsuite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-11T14:09:32.915246Z",
     "iopub.status.busy": "2022-08-11T14:09:32.914523Z",
     "iopub.status.idle": "2022-08-11T14:09:33.841335Z",
     "shell.execute_reply": "2022-08-11T14:09:33.839918Z",
     "shell.execute_reply.started": "2022-08-11T14:09:32.915207Z"
    }
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from sklearn_crfsuite import metrics\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "model = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Data Preprocessing**\n",
    "The dataset provided is in the form of one word per line. Let's understand the format of data below:\n",
    "\n",
    "Suppose there are x words in a sentence, then there will be x continuous lines with one word in each line.\n",
    "Further, the two sentences are separated by empty lines. The labels for the data follow the same format.\n",
    "We need to pre-process the data to recover the complete sentences and their labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-11T14:09:33.844718Z",
     "iopub.status.busy": "2022-08-11T14:09:33.844298Z",
     "iopub.status.idle": "2022-08-11T14:09:33.854802Z",
     "shell.execute_reply": "2022-08-11T14:09:33.853399Z",
     "shell.execute_reply.started": "2022-08-11T14:09:33.844685Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function to read the file if given filename\n",
    "def read_file(file_name):\n",
    "    with open(file_name, 'r', encoding='utf-8') as file:\n",
    "        content = file.readlines()\n",
    "    \n",
    "    sentences = []\n",
    "    sentence = \"\"\n",
    "    word_count = 0\n",
    "    \n",
    "    for word in content:\n",
    "        word = word.strip('\\n')\n",
    "        if word == \"\":\n",
    "            sentences.append(sentence.rstrip(\" \"))\n",
    "            sentence = \"\"\n",
    "        else:\n",
    "            word_count += 1\n",
    "            sentence += word + \" \"\n",
    "            \n",
    "    print(\"Items in File       : \", len(content))\n",
    "    print(\"Number of Words     : \", word_count)\n",
    "    print(\"Number of Sentences : \", len(sentences))\n",
    "    \n",
    "    prefix = \"First Sentence      :  \"\n",
    "    wrapper = textwrap.TextWrapper(initial_indent = prefix, width = 150, subsequent_indent = ' '*len(prefix))\n",
    "    print(wrapper.fill(sentences[0]))\n",
    "    \n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Count the number of sentences in the processed train and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-11T14:09:33.860207Z",
     "iopub.status.busy": "2022-08-11T14:09:33.856486Z",
     "iopub.status.idle": "2022-08-11T14:09:33.930580Z",
     "shell.execute_reply": "2022-08-11T14:09:33.929213Z",
     "shell.execute_reply.started": "2022-08-11T14:09:33.860143Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Training Sentences\")\n",
    "print(\"------------------\")\n",
    "train_sentences = read_file(\"../input/medical-entity-recognition-ner/Dataset/train_sent\")\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"Testing Sentences\")\n",
    "print(\"------------------\")\n",
    "test_sentences = read_file(\"../input/medical-entity-recognition-ner/Dataset/test_sent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-11T14:09:33.932850Z",
     "iopub.status.busy": "2022-08-11T14:09:33.932155Z",
     "iopub.status.idle": "2022-08-11T14:09:33.987660Z",
     "shell.execute_reply": "2022-08-11T14:09:33.986550Z",
     "shell.execute_reply.started": "2022-08-11T14:09:33.932803Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Training Labels\")\n",
    "print(\"--------------\")\n",
    "train_labels = read_file(\"../input/medical-entity-recognition-ner/Dataset/train_label\")\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"Testing Labels\")\n",
    "print(\"--------------\")\n",
    "test_labels = read_file(\"../input/medical-entity-recognition-ner/Dataset/test_label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-11T14:09:33.990199Z",
     "iopub.status.busy": "2022-08-11T14:09:33.989460Z",
     "iopub.status.idle": "2022-08-11T14:15:57.033083Z",
     "shell.execute_reply": "2022-08-11T14:15:57.031763Z",
     "shell.execute_reply.started": "2022-08-11T14:09:33.990158Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_pos_tags(reviews, labels, tag = \"\"):\n",
    "    \n",
    "    sentence = []\n",
    "    pos = []\n",
    "    lemma = []\n",
    "    text = []\n",
    "    label = []\n",
    "    \n",
    "    i = 1 # Sentence Count\n",
    "    \n",
    "    for review, review_labels in tqdm(zip(reviews, labels)):\n",
    "        #doc = model(review)\n",
    "        for doc, review_label in zip(review.split(), review_labels.split()):\n",
    "            s = model(doc)\n",
    "            for tok in s:\n",
    "                sentence.append(tag + str(i))\n",
    "                pos.append(tok.pos_)\n",
    "                lemma.append(tok.lemma_)\n",
    "                text.append(tok.text)\n",
    "                label.append(review_label)\n",
    "        \n",
    "        i += 1\n",
    "    \n",
    "    return sentence, pos, lemma, text, label\n",
    "\n",
    "print(\"Training Sentences\")\n",
    "print(\"------------------\")\n",
    "train_sentence, train_pos, train_lemma, train_text, train_label = get_pos_tags(train_sentences, train_labels, \"train_\")\n",
    "train_frequency_df = pd.DataFrame({'sentence':train_sentence, 'text':train_text,'lemma':train_lemma,'pos':train_pos,'label':train_label})\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"Testing Sentences\")\n",
    "print(\"------------------\")\n",
    "test_sentence, test_pos, test_lemma, test_text, test_label = get_pos_tags(test_sentences, test_labels, \"test_\")\n",
    "test_frequency_df = pd.DataFrame({'sentence':test_sentence, 'text':test_text,'lemma':test_lemma,'pos':test_pos,'label':test_label})\n",
    "\n",
    "# Convert the data into a dataframe object.\n",
    "frequency_df = pd.concat((train_frequency_df.copy(), test_frequency_df.copy()),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-11T14:15:57.035514Z",
     "iopub.status.busy": "2022-08-11T14:15:57.035099Z",
     "iopub.status.idle": "2022-08-11T14:15:57.087452Z",
     "shell.execute_reply": "2022-08-11T14:15:57.086050Z",
     "shell.execute_reply.started": "2022-08-11T14:15:57.035481Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get most frequent text forms of nouns\n",
    "frequency_df[(frequency_df['pos'] == 'NOUN') | (frequency_df['pos'] == 'PROPN')]['text'].value_counts()[:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-11T14:15:57.089804Z",
     "iopub.status.busy": "2022-08-11T14:15:57.089359Z",
     "iopub.status.idle": "2022-08-11T14:15:57.130240Z",
     "shell.execute_reply": "2022-08-11T14:15:57.128859Z",
     "shell.execute_reply.started": "2022-08-11T14:15:57.089767Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get most frequent lemma forms of nouns\n",
    "frequency_df[(frequency_df['pos'] == 'NOUN') | (frequency_df['pos'] == 'PROPN')]['lemma'].value_counts()[:25]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining features for CRF\n",
    "We have defined the following features for CRF modeule building:\n",
    "\n",
    "f1 = input word is in lower case;\n",
    "f2 = last 3 characters of word;\n",
    "f3 = last 2 characters of word;\n",
    "f4 = 1; if the word is in uppercase; otherwise, 0\n",
    "f5 = 1; if the word is a number; otherwise, 0\n",
    "f6 = 1; if the word starts with a capital letter; otherwise, 0\n",
    "f7 = 1; if PoS Tag of the word is Noun or Pronoun; otherwise, 0\n",
    "f8 = 1; if PoS Tag of the word is Noun or Pronoun; otherwise, 0\n",
    "f9 = B; if beginning\n",
    "f10 = E; if ending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-11T14:15:57.136136Z",
     "iopub.status.busy": "2022-08-11T14:15:57.135343Z",
     "iopub.status.idle": "2022-08-11T14:15:57.151903Z",
     "shell.execute_reply": "2022-08-11T14:15:57.150697Z",
     "shell.execute_reply.started": "2022-08-11T14:15:57.136080Z"
    }
   },
   "outputs": [],
   "source": [
    "# Let's define the features to get the feature value for one word.\n",
    "def getFeaturesForOneWord(word_details, pos):\n",
    "    word_details.reset_index(drop=True, inplace=True)\n",
    "    word = word_details[pos][0]\n",
    "    postag = word_details[pos][1]\n",
    "    \n",
    "    features = [\n",
    "        'bias=' + \"1.0\",\n",
    "        'word.lower=' + word.lower(),\n",
    "        'word[-3]=' + word[:-3],\n",
    "        'word[-2]=' + word[:-2],\n",
    "        'word.islower=%s' % word.islower(),\n",
    "        'word.isupper=%s' % word.isupper(),\n",
    "        'word.istitle=%s' % word.istitle(),\n",
    "        'word.isdigit=%s' % word.isdigit(),\n",
    "        'postag=' + postag,\n",
    "        'postag.isnounpronoun=%s' % (postag in ['NOUN','PROPN']),\n",
    "    ]\n",
    "    \n",
    "    if (pos > 0):\n",
    "        prev_word = word_details[pos-1][0]\n",
    "        prev_postag = word_details[pos-1][1]\n",
    "        \n",
    "        features.extend([\n",
    "            'prev_word.lower=' + prev_word.lower(),\n",
    "            'prev_word[-3]=' + prev_word[:-3],\n",
    "            'prev_word[-2]=' + prev_word[:-2],\n",
    "            'prev_word.islower=%s' % prev_word.islower(),\n",
    "            'prev_word.isupper=%s' % prev_word.isupper(),\n",
    "            'prev_word.istitle=%s' % prev_word.istitle(),\n",
    "            'prev_word.isdigit=%s' % prev_word.isdigit(),\n",
    "            'prev_postag=' + prev_postag,\n",
    "            'prev_postag.isnounpronoun=%s' % (prev_postag in ['NOUN','PROPN']),\n",
    "        ])\n",
    "    else:\n",
    "        features.append('BEG')\n",
    "        \n",
    "    if (pos < len(word_details) - 1):\n",
    "        next_word = word_details[pos+1][0]\n",
    "        next_postag = word_details[pos+1][1]\n",
    "        \n",
    "        features.extend([\n",
    "            'next_word.lower=' + next_word.lower(),\n",
    "            'next_word[-3]=' + next_word[:-3],\n",
    "            'next_word[-2]=' + next_word[:-2],\n",
    "            'next_word.islower=%s' % next_word.islower(),\n",
    "            'next_word.isupper=%s' % next_word.isupper(),\n",
    "            'next_word.istitle=%s' % next_word.istitle(),\n",
    "            'next_word.isdigit=%s' % next_word.isdigit(),\n",
    "            'next_postag=' + next_postag,\n",
    "            'next_postag.isnounpronoun=%s' % (next_postag in ['NOUN','PROPN']),\n",
    "        ])\n",
    "    else:\n",
    "        features.append('END')\n",
    "        \n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the features\n",
    "Write a code/function to get the features for a sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-11T14:15:57.154313Z",
     "iopub.status.busy": "2022-08-11T14:15:57.153347Z",
     "iopub.status.idle": "2022-08-11T14:15:57.170904Z",
     "shell.execute_reply": "2022-08-11T14:15:57.169738Z",
     "shell.execute_reply.started": "2022-08-11T14:15:57.154267Z"
    }
   },
   "outputs": [],
   "source": [
    "# Write a code to get features for a sentence.\n",
    "def get_word_details(item):\n",
    "    return item[\"text\"], item[\"pos\"]\n",
    "\n",
    "def getFeaturesForOneSentence(sentence_id):\n",
    "    words_for_features = frequency_df[frequency_df[\"sentence\"] == sentence_id].apply(get_word_details, axis=1)\n",
    "    return [getFeaturesForOneWord(words_for_features, pos) for pos in range(len(words_for_features))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-11T14:15:57.172948Z",
     "iopub.status.busy": "2022-08-11T14:15:57.172519Z",
     "iopub.status.idle": "2022-08-11T14:15:57.215893Z",
     "shell.execute_reply": "2022-08-11T14:15:57.214526Z",
     "shell.execute_reply.started": "2022-08-11T14:15:57.172902Z"
    }
   },
   "outputs": [],
   "source": [
    "features = getFeaturesForOneSentence(\"train_1\")\n",
    "prefix = \"01 Sentence : \"\n",
    "wrapper = textwrap.TextWrapper(initial_indent = prefix, width = 150, subsequent_indent = ' '*len(prefix))\n",
    "print(wrapper.fill(train_sentences[0]))\n",
    "print('\\n')\n",
    "\n",
    "i = 1\n",
    "for feature in features:\n",
    "    prefix = str('%02d' % i) + \" Word     : \"\n",
    "    wrapper = textwrap.TextWrapper(initial_indent = prefix, width = 150, subsequent_indent = ' '*len(prefix))\n",
    "    print(wrapper.fill(str(feature)))\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-11T14:15:57.218248Z",
     "iopub.status.busy": "2022-08-11T14:15:57.217854Z",
     "iopub.status.idle": "2022-08-11T14:15:57.223568Z",
     "shell.execute_reply": "2022-08-11T14:15:57.222447Z",
     "shell.execute_reply.started": "2022-08-11T14:15:57.218216Z"
    }
   },
   "outputs": [],
   "source": [
    "# Write a code to get the labels for a sentence.\n",
    "def getLabelsForOneSentence(sentence_id):\n",
    "    return frequency_df[frequency_df[\"sentence\"] == sentence_id][\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-11T14:15:57.226357Z",
     "iopub.status.busy": "2022-08-11T14:15:57.225110Z",
     "iopub.status.idle": "2022-08-11T14:15:57.250462Z",
     "shell.execute_reply": "2022-08-11T14:15:57.248868Z",
     "shell.execute_reply.started": "2022-08-11T14:15:57.226316Z"
    }
   },
   "outputs": [],
   "source": [
    "labels = getLabelsForOneSentence(\"train_1\")\n",
    "\n",
    "prefix = \"01 Labels  : \"\n",
    "wrapper = textwrap.TextWrapper(initial_indent = prefix, width = 150, subsequent_indent = ' '*len(prefix))\n",
    "print(wrapper.fill(\" \".join(labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define input and target variables\n",
    "Correctly computing X and Y sequence matrices for training and test data. Check that both sentences and labels are processed\n",
    "\n",
    "Define the features' values for each sentence as input variable for CRF model in test and the train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-11T14:15:57.253084Z",
     "iopub.status.busy": "2022-08-11T14:15:57.252402Z",
     "iopub.status.idle": "2022-08-11T14:16:45.520659Z",
     "shell.execute_reply": "2022-08-11T14:16:45.519344Z",
     "shell.execute_reply.started": "2022-08-11T14:15:57.253039Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Training Sentences\")\n",
    "print(\"------------------\")\n",
    "X_train = [getFeaturesForOneSentence(\"train_\" + str(i+1)) for i in tqdm(range(len(train_sentences)))] \n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"Testing Sentences\")\n",
    "print(\"------------------\")\n",
    "X_test = [getFeaturesForOneSentence(\"test_\" + str(i+1)) for i in tqdm(range(len(test_sentences)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-11T14:16:45.523425Z",
     "iopub.status.busy": "2022-08-11T14:16:45.522839Z",
     "iopub.status.idle": "2022-08-11T14:17:25.824636Z",
     "shell.execute_reply": "2022-08-11T14:17:25.823571Z",
     "shell.execute_reply.started": "2022-08-11T14:16:45.523371Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Training Labels\")\n",
    "print(\"------------------\")\n",
    "Y_train = [getLabelsForOneSentence(\"train_\" + str(i+1)) for i in tqdm(range(len(train_labels)))] \n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"Testing Labels\")\n",
    "print(\"------------------\")\n",
    "Y_test = [getLabelsForOneSentence(\"test_\" + str(i+1)) for i in tqdm(range(len(test_labels)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-11T14:17:59.514907Z",
     "iopub.status.busy": "2022-08-11T14:17:59.514254Z",
     "iopub.status.idle": "2022-08-11T14:18:09.544439Z",
     "shell.execute_reply": "2022-08-11T14:18:09.543161Z",
     "shell.execute_reply.started": "2022-08-11T14:17:59.514863Z"
    }
   },
   "outputs": [],
   "source": [
    "# Build the CRF model.\n",
    "crf = sklearn_crfsuite.CRF(c1=0.1, c2=0.1, max_iterations=100, all_possible_transitions=True)\n",
    "try:\n",
    "    crf.fit(X_train, Y_train)\n",
    "except AttributeError:\n",
    "    pass\n",
    "predictions = crf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "Predict the labels of each of the tokens in each sentence of the test dataset that has been pre processed earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-11T14:18:18.428572Z",
     "iopub.status.busy": "2022-08-11T14:18:18.428090Z",
     "iopub.status.idle": "2022-08-11T14:18:18.673847Z",
     "shell.execute_reply": "2022-08-11T14:18:18.672074Z",
     "shell.execute_reply.started": "2022-08-11T14:18:18.428533Z"
    }
   },
   "outputs": [],
   "source": [
    "Y_pred = crf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the f1 score using the actual labels and the predicted labels of the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-11T14:18:23.852481Z",
     "iopub.status.busy": "2022-08-11T14:18:23.851998Z",
     "iopub.status.idle": "2022-08-11T14:18:24.029003Z",
     "shell.execute_reply": "2022-08-11T14:18:24.027227Z",
     "shell.execute_reply.started": "2022-08-11T14:18:23.852445Z"
    }
   },
   "outputs": [],
   "source": [
    "f1_score = metrics.flat_f1_score(Y_test, Y_pred, average='weighted')\n",
    "print('Predicted F1-Score : {0} % '.format(round(f1_score*100,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identifying Diseases and Treatments using Custom NER\n",
    "We now use the CRF model's prediction to prepare a record of diseases identified in the corpus and treatments used for the diseases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-11T14:18:31.388835Z",
     "iopub.status.busy": "2022-08-11T14:18:31.388341Z",
     "iopub.status.idle": "2022-08-11T14:18:31.414892Z",
     "shell.execute_reply": "2022-08-11T14:18:31.413448Z",
     "shell.execute_reply.started": "2022-08-11T14:18:31.388798Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_labels_as_array(labels):\n",
    "    pred_label = []\n",
    "\n",
    "    for label in labels:\n",
    "        pred_label.extend(label)\n",
    "        \n",
    "    return pred_label\n",
    "\n",
    "test_frequency_df[\"pred_label\"] = get_labels_as_array(Y_pred)\n",
    "test_frequency_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-11T14:18:39.972709Z",
     "iopub.status.busy": "2022-08-11T14:18:39.972264Z",
     "iopub.status.idle": "2022-08-11T14:18:40.522636Z",
     "shell.execute_reply": "2022-08-11T14:18:40.521008Z",
     "shell.execute_reply.started": "2022-08-11T14:18:39.972660Z"
    }
   },
   "outputs": [],
   "source": [
    "new_df = test_frequency_df[(test_frequency_df.pred_label != 'O')]\n",
    "new_df.set_index('sentence',inplace=True)\n",
    "\n",
    "disease=[]\n",
    "treatment=[]\n",
    "sentence=[]\n",
    "med_dict = {}\n",
    "\n",
    "for i in new_df.index.unique():\n",
    "    try:\n",
    "        val = new_df.loc[i,'pred_label'].unique()\n",
    "        if len(val) == 2:\n",
    "            disease_val = new_df[new_df.pred_label == 'D'].loc[i,'text']\n",
    "            treatment_val = new_df[new_df.pred_label == 'T'].loc[i,'text']\n",
    "            disease_single = disease_val if type(disease_val) == str else \" \".join(disease_val)\n",
    "            treatment_single = treatment_val if type(treatment_val) == str else \" \".join(treatment_val)\n",
    "            if disease_single not in disease:\n",
    "                med_dict[disease_single] = treatment_single\n",
    "            else:\n",
    "                print('Entered')\n",
    "                med_dict[disease_single] = med_dict.get(disease_single)+'/'+treatment_single\n",
    "    except AttributeError:\n",
    "        pass\n",
    "\n",
    "print(json.dumps(dict(sorted(med_dict.items())), indent = 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-11T14:18:58.604332Z",
     "iopub.status.busy": "2022-08-11T14:18:58.603179Z",
     "iopub.status.idle": "2022-08-11T14:18:58.626360Z",
     "shell.execute_reply": "2022-08-11T14:18:58.625311Z",
     "shell.execute_reply.started": "2022-08-11T14:18:58.604286Z"
    }
   },
   "outputs": [],
   "source": [
    "disease=''\n",
    "treatment=''\n",
    "\n",
    "input_text = []\n",
    "input_pos = []\n",
    "input_label = []\n",
    "\n",
    "input_sent = 'hereditary retinoblastoma'\n",
    "\n",
    "input_model = model(input_sent)\n",
    "\n",
    "for word in input_model:\n",
    "    input_text.append(word.text)\n",
    "    input_pos.append(word.pos_)\n",
    "    input_label.append('D')\n",
    "\n",
    "details_sent = pd.DataFrame({'text':input_text, 'pos':input_pos,'label':input_label})\n",
    "words_for_features = details_sent.apply(get_word_details, axis=1)\n",
    "\n",
    "test_sent = []\n",
    "\n",
    "for i in range(len(input_sent.split())):\n",
    "    test_sent.append(getFeaturesForOneWord(words_for_features, i))\n",
    "\n",
    "for i,tag in enumerate(crf.predict([test_sent])[0]):\n",
    "    \n",
    "    if tag == 'D':\n",
    "        tr = input_sent.split()[i]\n",
    "        disease += tr + \" \"\n",
    "\n",
    "        if tr in med_dict:\n",
    "            treatment += med_dict.get(tr) + \", \"\n",
    "            \n",
    "        if disease.strip() in med_dict:\n",
    "            treatment += med_dict.get(disease.strip()) + \", \"\n",
    "\n",
    "disease = disease.strip()\n",
    "\n",
    "if len(treatment) == 0:\n",
    "    treatment = 'Not Available'\n",
    "else:\n",
    "    treatment = treatment.rstrip(\", \")\n",
    "    \n",
    "print('Identified Disease   :', disease)\n",
    "print('Identified Treatment :', treatment)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
